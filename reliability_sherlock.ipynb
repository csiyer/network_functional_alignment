{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed3af014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/csiyer/.local/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 3.2.1'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# import glob\n",
    "import seaborn as sns\n",
    "sns.set(palette=\"colorblind\")\n",
    "import matplotlib.pyplot as plt\n",
    "from pingouin import intraclass_corr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a47aeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_filenames():\n",
    "    files = []\n",
    "    d = '/scratch/users/csiyer/'\n",
    "    for sub in ['sub-s03', 'sub-s10', 'sub-s19', 'sub-s29', 'sub-s43']:\n",
    "        for ses in ['_ses-' + str(n).zfill(2) for n in range(1,13)]:\n",
    "            files.append(d + sub + ses + '_connectome.npy')\n",
    "    return files\n",
    "\n",
    "# load connectomes\n",
    "def load_connectomes():\n",
    "\n",
    "    data_dict = {}\n",
    "    for sub in np.unique([f[f.find('sub'):f.find('sub')+7] for f in glob.glob('outputs/connectomes/*ses*')]):\n",
    "        data_dict[sub] = {}\n",
    "        for ses in np.unique([f[f.find('ses'):f.find('ses')+6] for f in glob.glob(f'outputs/connectomes/*{sub}*ses*')]):\n",
    "            curr = np.load(glob.glob(f'outputs/connectomes/*{sub}_{ses}*')[0])\n",
    "            data_dict[sub][ses] = {\n",
    "                'connectome': curr, # save memory without this\n",
    "                # 'connectome_flat': curr.flatten()\n",
    "            }\n",
    "\n",
    "    # connectomes_flat = []\n",
    "    # for sub in data_dict.keys():\n",
    "    #     for ses, data in data_dict[sub].items():\n",
    "    #         connectomes_flat.append(data['connectome_flat'])\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "def load_connectomes_flat(sub=''):\n",
    "    \n",
    "    files = manual_filenames()\n",
    "    \n",
    "    # connectomes_flat = pd.DataFrame() \n",
    "    connectomes_flat = []\n",
    "    \n",
    "    subcount, sescount = (0,0)\n",
    "    \n",
    "    for sub in np.unique([f[f.find('sub'):f.find('sub')+7] for f in files]):\n",
    "        subcount += 1\n",
    "        sescount = 0\n",
    "        for ses in np.unique([f[f.find('ses'):f.find('ses')+6] for f in [f_sub for f_sub in files if sub in f_sub]]):\n",
    "            sescount +=1\n",
    "            \n",
    "            # connectomes_flat[sub+ses] = np.load([f for f in files if sub in f and ses in f][0]).flatten()\n",
    "            connectomes_flat.append( np.load([f for f in files if sub in f and ses in f][0]).flatten() )\n",
    "\n",
    "    return connectomes_flat, subcount, sescount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165d2c5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data_dict, connectomes_flat = load_connectomes()\n",
    "connectomes_flat, n_subjects, n_sessions = load_connectomes_flat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4880cf",
   "metadata": {},
   "source": [
    "RDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7f2c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation matrix of connectivity vectors\n",
    "similarity_matrix = connectomes_flat.corr() # get_correlation_matrix()\n",
    "similarity_matrix.shape # should be 60x60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1067f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the similarity matrix \n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,8))\n",
    "\n",
    "sns.heatmap(similarity_matrix, ax=ax)\n",
    "\n",
    "# Add lines to box off every num_ses entries (each subject)\n",
    "for i in range(0, similarity_matrix.shape[0], n_sessions):\n",
    "    ax.axhline(i, color='white', linewidth=2)\n",
    "    ax.axvline(i, color='white', linewidth=2)\n",
    "\n",
    "xtick_labels = ['sub-s03', 'sub-s10', 'sub-s19', 'sub-s29', 'sub-s43']\n",
    "xtick_positions = np.arange(n_sessions/2, similarity_matrix.shape[1], n_sessions)\n",
    "ax.set_xticks(xtick_positions)\n",
    "ax.set_xticklabels(xtick_labels)\n",
    "ax.set_yticks(xtick_positions)\n",
    "ax.set_yticklabels(xtick_labels)\n",
    "ax.set_title(\"Session-wise Connectivity Similarity Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0cef57",
   "metadata": {},
   "source": [
    "ICC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9505dda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(connectomes_flat)\n",
    "data_long = pd.DataFrame(data.flatten(), columns=['connectivity_values'])\n",
    "data_long['subjects'] = np.repeat(range(n_subjects), n_sessions*data.shape[1]) \n",
    "data_long['sessions'] = np.tile(np.repeat(range(n_sessions), data.shape[1]), n_subjects)  # 12 sessions for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2534574",
   "metadata": {},
   "outputs": [],
   "source": [
    "icc = intraclass_corr(data=data_long, targets='subjects', raters='sessions', ratings='connectivity_values').set_index('Type')\n",
    "print(icc.loc['ICC2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905b68e5",
   "metadata": {},
   "source": [
    "split half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc27def7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 1000\n",
    "avg_within_sub_corr = []\n",
    "avg_across_sub_corr = []\n",
    "\n",
    "for i_iter in range(n_iter):\n",
    "\n",
    "    # split data into halves and calculate the mean of the half\n",
    "    split_dict = {} # for storing values during these calculations\n",
    "\n",
    "    for sub in data_dict.keys():\n",
    "        split_dict[sub] = {}\n",
    "        rand_ses = list(np.random.permutation(list(data_dict[sub].keys())))\n",
    "        group1data = []\n",
    "        group2data = []\n",
    "\n",
    "        for ses, data in data_dict[sub].items():\n",
    "            if rand_ses.index(ses) > len(rand_ses)/2-1:\n",
    "                # if in the second half of randomized list\n",
    "                group1data.append(data['connectome_flat'])\n",
    "            else:\n",
    "                group2data.append(data['connectome_flat'])\n",
    "        \n",
    "        split_dict[sub]['group1_mean'] = np.mean(group1data, axis=0)\n",
    "        split_dict[sub]['group2_mean'] = np.mean(group2data, axis=0)\n",
    "\n",
    "    # iterate again and calculate correlation with each other group\n",
    "    within_sub_corr = []\n",
    "    across_sub_corr = []\n",
    "    for sub in split_dict.keys():\n",
    "        # save correlation of that sub's two halves\n",
    "        within_sub_corr.append(np.corrcoef(split_dict[sub]['group1_mean'], split_dict[sub]['group2_mean']))\n",
    "\n",
    "        # calculate correlation of each of those to all others \n",
    "        for sub_two in split_dict.keys():\n",
    "            if sub_two != sub:\n",
    "                across_sub_corr.append(np.corrcoef(split_dict[sub]['group1_mean'], split_dict[sub_two]['group1_mean']))\n",
    "                across_sub_corr.append(np.corrcoef(split_dict[sub]['group1_mean'], split_dict[sub_two]['group2_mean']))\n",
    "                across_sub_corr.append(np.corrcoef(split_dict[sub]['group2_mean'], split_dict[sub_two]['group1_mean']))\n",
    "                across_sub_corr.append(np.corrcoef(split_dict[sub]['group2_mean'], split_dict[sub_two]['group2_mean']))\n",
    "\n",
    "    avg_within_sub_corr.append(np.mean(within_sub_corr))\n",
    "    avg_across_sub_corr.append(np.mean(across_sub_corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa5a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "fig, ax = plt.subplots(1,1)\n",
    "fig.suptitle('Within-subject vs. across-subject split-half connectome reliability across 1000 iterations')\n",
    "ax.boxplot(avg_within_sub_corr, positions=[1], patch_artist=True, boxprops=dict(facecolor='blue'), labels=['Within-subject'])\n",
    "ax.boxplot(avg_within_sub_corr, positions=[2], patch_artist=True, boxprops=dict(facecolor='red'), labels=['Across-subject'])\n",
    "ax.set_ylabel('Pearson r of split halves')\n",
    "ax.set_ylim(0,1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
