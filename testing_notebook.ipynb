{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current questions / problems\n",
    "\n",
    "- write searchlight loading\n",
    "- convert voxel FC to FCMA from brainiak\n",
    "    - Cython issues..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from nilearn import datasets\n",
    "from nilearn.maskers import MultiNiftiMasker, MultiNiftiLabelsMasker, NiftiSpheresMasker\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(FILE_PATHS=[], \n",
    "            strategy = 'parcel', \n",
    "            schaefer_n_rois=400, \n",
    "            sphere_radius=8, \n",
    "            sphere_spacing=6):\n",
    "    \"\"\"This function loads data in 3 different ways:\n",
    "        1. Strategy = voxel: extracts direct voxel timeseries\n",
    "        2. Strategy = parcel: extracts parcel timeseries from schaefer 2018 atlas with a given # of ROIs\n",
    "        3. Strategy = searchlight: extracts timeseries of spheres of a given radius and spacing\n",
    "\n",
    "        NOTE: the masker.fit_transform function returns an array of the shape (n_TRs x n_voxels)\n",
    "        \"\"\"\n",
    "\n",
    "    if FILE_PATHS == []:\n",
    "        FILE_PATHS = glob.glob('data/rest/*.nii.gz') # all rest data by default\n",
    "\n",
    "    masker_args = {\n",
    "        'standardize': 'zscore_sample', # ??\n",
    "        'n_jobs': -1,\n",
    "        # not doing any: mask_img, smoothing, detrend, standardize, low_pass, high_pass, t_r\n",
    "    }\n",
    "\n",
    "    if strategy == 'voxel':\n",
    "        masker = MultiNiftiMasker(mask_strategy = 'whole-brain-template', # or gm-template?\n",
    "                                  **masker_args)\n",
    "\n",
    "    elif strategy == 'parcel':\n",
    "        schaefer_atlas = datasets.fetch_atlas_schaefer_2018(n_rois=schaefer_n_rois, \n",
    "                                                        yeo_networks=7, \n",
    "                                                        resolution_mm=2, # because our data is too\n",
    "                                                        data_dir='data/schaefer', \n",
    "                                                        verbose=0)\n",
    "        masker = MultiNiftiLabelsMasker(labels_img = schaefer_atlas.maps,\n",
    "                                labels = schaefer_atlas.labels,\n",
    "                                resampling_target = 'data',\n",
    "                                strategy = 'mean',\n",
    "                                **masker_args)\n",
    "\n",
    "    elif strategy == 'searchlight':\n",
    "        sphere_coords = [] # get the centerpoint coordinates of spheres. These ranges from chatGPT so def need to check\n",
    "        for x in range(-90, 91, sphere_spacing):\n",
    "            for y in range(-126, 91, sphere_spacing):\n",
    "                for z in range(-72, 73, sphere_spacing):\n",
    "                    sphere_coords.append((x, y, z))\n",
    "        masker = NiftiSpheresMasker(seeds = sphere_coords, \n",
    "                                    radius=sphere_radius, \n",
    "                                    **masker_args)\n",
    "        # NOTE: change this to match dimensionality of whatever the others are outputting\n",
    "        return [masker.fit_transform(f) for f in FILE_PATHS]\n",
    "\n",
    "    # this only works for the multimaskers with voxel/parcel\n",
    "    return masker.fit_transform(FILE_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fc_voxel(voxel_timeseries, cov_estimator=EmpiricalCovariance()):\n",
    "    \"\"\"Full voxel-to-voxel connectivity/correlation matrix\n",
    "    NOTES:\n",
    "        - This will take forever with the current implementation -- *replace with FCMA toolbox?*\n",
    "        - Default nilearn covariance estimator is LedoitWolf, replacing here with EmpiricalCovariance() for pearson\n",
    "    \"\"\"\n",
    "    correlation_measure = ConnectivityMeasure(kind=\"correlation\", cov_estimator=cov_estimator)\n",
    "    return correlation_measure.fit_transform(voxel_timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlate_rows(mat1, mat2):\n",
    "    # matrix with the Pearson r correlation of each column (voxel) of mat1 with each column (parcel/target) of mat2\n",
    "    correlation_matrix = np.empty((mat1.shape[1], mat2.shape[1]))\n",
    "    for i in range(mat1.shape[0]):\n",
    "        for j in range(mat2.shape[0]):\n",
    "            correlation_matrix[i, j] = pearsonr(mat1[:, i], mat2[:, j])[0]\n",
    "    return correlation_matrix\n",
    "\n",
    "def compute_fc_target(voxel_timeseries, target_timeseries):\n",
    "    \"\"\"Voxel-to-connectivity_target correlation \n",
    "    Connectivity targets could be the parcel timeseries, or a searchlight timeseries\n",
    "\n",
    "    This will take each column in the voxel timeseries (across all the TRs/rows) \n",
    "    and correlate it with each column in the target timeseries.\n",
    "\n",
    "    NOTE: The connectivity target in which a given voxel resides is not excluded yet -- should it be?\n",
    "    \"\"\"\n",
    "    return np.array([correlate_rows(voxel_timeseries[i], target_timeseries[i]) for i in range(len(voxel_timeseries))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('data/rest/*.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_data = load_data(FILE_PATHS = [files[0]], strategy='voxel')\n",
    "parcel_data = load_data(FILE_PATHS = [files[0]], strategy='parcel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ciyer\\miniconda3\\envs\\lab\\Lib\\site-packages\\nilearn\\connectome\\connectivity_matrices.py:495: FutureWarning: The default strategy for standardize is currently 'zscore' which incorrectly uses population std to calculate sample zscores. The new strategy 'zscore_sample' corrects this behavior by using the sample std. In release 0.13, the default strategy will be replaced by the new strategy and the 'zscore' option will be removed. Please use 'zscore_sample' instead.\n",
      "  covariances_std = [\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.82989885, 0.9214724 ],\n",
       "       [0.82989885, 1.        , 0.78760728],\n",
       "       [0.9214724 , 0.78760728, 1.        ]])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fc = compute_fc_voxel(parcel_data, cov_estimator=EmpiricalCovariance())\n",
    "test_fc[0,0:3,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78696161, 0.68935141, 0.81799557],\n",
       "       [0.73036263, 0.58372468, 0.78881791],\n",
       "       [0.82763582, 0.65915864, 0.84305991]])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fc2 = compute_fc_target(voxel_data, parcel_data)\n",
    "test_fc2[0][0:3, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[316], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m masker \u001b[39m=\u001b[39m NiftiSpheresMasker(seeds \u001b[39m=\u001b[39m sphere_coords, \n\u001b[0;32m     16\u001b[0m                             radius\u001b[39m=\u001b[39msphere_radius, \n\u001b[0;32m     17\u001b[0m                             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmasker_args)\n\u001b[0;32m     18\u001b[0m \u001b[39m# NOTE: change this to match dimensionality of whatever the others are outputting\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m test \u001b[39m=\u001b[39m [masker\u001b[39m.\u001b[39;49mfit_transform(f) \u001b[39mfor\u001b[39;49;00m f \u001b[39min\u001b[39;49;00m FILE_PATHS]\n",
      "Cell \u001b[1;32mIn[316], line 19\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     15\u001b[0m masker \u001b[39m=\u001b[39m NiftiSpheresMasker(seeds \u001b[39m=\u001b[39m sphere_coords, \n\u001b[0;32m     16\u001b[0m                             radius\u001b[39m=\u001b[39msphere_radius, \n\u001b[0;32m     17\u001b[0m                             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmasker_args)\n\u001b[0;32m     18\u001b[0m \u001b[39m# NOTE: change this to match dimensionality of whatever the others are outputting\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m test \u001b[39m=\u001b[39m [masker\u001b[39m.\u001b[39;49mfit_transform(f) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m FILE_PATHS]\n",
      "File \u001b[1;32mc:\\Users\\ciyer\\miniconda3\\envs\\lab\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\ciyer\\miniconda3\\envs\\lab\\Lib\\site-packages\\nilearn\\maskers\\nifti_spheres_masker.py:401\u001b[0m, in \u001b[0;36mNiftiSpheresMasker.fit_transform\u001b[1;34m(self, imgs, confounds, sample_mask)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, imgs, confounds\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    371\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Prepare and perform signal extraction.\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \n\u001b[0;32m    373\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    399\u001b[0m \n\u001b[0;32m    400\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 401\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit()\u001b[39m.\u001b[39;49mtransform(imgs, confounds\u001b[39m=\u001b[39;49mconfounds,\n\u001b[0;32m    402\u001b[0m                                 sample_mask\u001b[39m=\u001b[39;49msample_mask)\n",
      "File \u001b[1;32mc:\\Users\\ciyer\\miniconda3\\envs\\lab\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\ciyer\\miniconda3\\envs\\lab\\Lib\\site-packages\\nilearn\\maskers\\base_masker.py:232\u001b[0m, in \u001b[0;36mBaseMasker.transform\u001b[1;34m(self, imgs, confounds, sample_mask)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fitted()\n\u001b[0;32m    231\u001b[0m \u001b[39mif\u001b[39;00m confounds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhigh_variance_confounds:\n\u001b[1;32m--> 232\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_single_imgs(imgs,\n\u001b[0;32m    233\u001b[0m                                       confounds\u001b[39m=\u001b[39;49mconfounds,\n\u001b[0;32m    234\u001b[0m                                       sample_mask\u001b[39m=\u001b[39;49msample_mask)\n\u001b[0;32m    236\u001b[0m \u001b[39m# Compute high variance confounds if requested\u001b[39;00m\n\u001b[0;32m    237\u001b[0m all_confounds \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\ciyer\\miniconda3\\envs\\lab\\Lib\\site-packages\\nilearn\\maskers\\nifti_spheres_masker.py:454\u001b[0m, in \u001b[0;36mNiftiSpheresMasker.transform_single_imgs\u001b[1;34m(self, imgs, confounds, sample_mask)\u001b[0m\n\u001b[0;32m    451\u001b[0m params \u001b[39m=\u001b[39m get_params(NiftiSpheresMasker, \u001b[39mself\u001b[39m)\n\u001b[0;32m    452\u001b[0m params[\u001b[39m'\u001b[39m\u001b[39mclean_kwargs\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclean_kwargs\n\u001b[1;32m--> 454\u001b[0m signals, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cache(\n\u001b[0;32m    455\u001b[0m     _filter_and_extract,\n\u001b[0;32m    456\u001b[0m     ignore\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mverbose\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mmemory\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mmemory_level\u001b[39;49m\u001b[39m'\u001b[39;49m])(\n\u001b[0;32m    457\u001b[0m         imgs,\n\u001b[0;32m    458\u001b[0m         _ExtractionFunctor(\n\u001b[0;32m    459\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseeds_, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mradius, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmask_img,\n\u001b[0;32m    460\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mallow_overlap, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype\n\u001b[0;32m    461\u001b[0m         ),\n\u001b[0;32m    462\u001b[0m         \u001b[39m# Pre-processing\u001b[39;49;00m\n\u001b[0;32m    463\u001b[0m         params,\n\u001b[0;32m    464\u001b[0m         confounds\u001b[39m=\u001b[39;49mconfounds,\n\u001b[0;32m    465\u001b[0m         sample_mask\u001b[39m=\u001b[39;49msample_mask,\n\u001b[0;32m    466\u001b[0m         dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype,\n\u001b[0;32m    467\u001b[0m         \u001b[39m# Caching\u001b[39;49;00m\n\u001b[0;32m    468\u001b[0m         memory\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmemory,\n\u001b[0;32m    469\u001b[0m         memory_level\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmemory_level,\n\u001b[0;32m    470\u001b[0m         \u001b[39m# kwargs\u001b[39;49;00m\n\u001b[0;32m    471\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose\n\u001b[0;32m    472\u001b[0m )\n\u001b[0;32m    473\u001b[0m \u001b[39mreturn\u001b[39;00m signals\n",
      "File \u001b[1;32mc:\\Users\\ciyer\\miniconda3\\envs\\lab\\Lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ciyer\\miniconda3\\envs\\lab\\Lib\\site-packages\\nilearn\\maskers\\base_masker.py:106\u001b[0m, in \u001b[0;36m_filter_and_extract\u001b[1;34m(imgs, extraction_function, parameters, memory_level, memory, verbose, confounds, sample_mask, copy, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    105\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m{\u001b[39;00mclass_name\u001b[39m}\u001b[39;00m\u001b[39m] Extracting region signals\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 106\u001b[0m region_signals, aux \u001b[39m=\u001b[39m cache(extraction_function, memory,\n\u001b[0;32m    107\u001b[0m                             func_memory_level\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[0;32m    108\u001b[0m                             memory_level\u001b[39m=\u001b[39;49mmemory_level)(imgs)\n\u001b[0;32m    110\u001b[0m \u001b[39m# Temporal\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[39m# --------\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[39m# Detrending (optional)\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[39m# Filtering\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[39m# Confounds removing (from csv file or numpy array)\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39m# Normalizing\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ciyer\\miniconda3\\envs\\lab\\Lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ciyer\\miniconda3\\envs\\lab\\Lib\\site-packages\\nilearn\\maskers\\nifti_spheres_masker.py:205\u001b[0m, in \u001b[0;36m_ExtractionFunctor.__call__\u001b[1;34m(self, imgs)\u001b[0m\n\u001b[0;32m    199\u001b[0m imgs \u001b[39m=\u001b[39m check_niimg_4d(imgs, dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m    201\u001b[0m signals \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(\n\u001b[0;32m    202\u001b[0m     (imgs\u001b[39m.\u001b[39mshape[\u001b[39m3\u001b[39m], n_seeds),\n\u001b[0;32m    203\u001b[0m     dtype\u001b[39m=\u001b[39mimg_data_dtype(imgs)\n\u001b[0;32m    204\u001b[0m )\n\u001b[1;32m--> 205\u001b[0m \u001b[39mfor\u001b[39;00m i, sphere \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(_iter_signals_from_spheres(\n\u001b[0;32m    206\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseeds_, imgs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mradius, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mallow_overlap,\n\u001b[0;32m    207\u001b[0m         mask_img\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmask_img)):\n\u001b[0;32m    208\u001b[0m     signals[:, i] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(sphere, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    209\u001b[0m \u001b[39mreturn\u001b[39;00m signals, \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ciyer\\miniconda3\\envs\\lab\\Lib\\site-packages\\nilearn\\maskers\\nifti_spheres_masker.py:179\u001b[0m, in \u001b[0;36m_iter_signals_from_spheres\u001b[1;34m(seeds, niimg, radius, allow_overlap, mask_img)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_iter_signals_from_spheres\u001b[39m(seeds, niimg, radius, allow_overlap,\n\u001b[0;32m    152\u001b[0m                                mask_img\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    153\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Iterate over spheres.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \n\u001b[0;32m    155\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m     X, A \u001b[39m=\u001b[39m _apply_mask_and_get_affinity(seeds, niimg, radius,\n\u001b[0;32m    180\u001b[0m                                         allow_overlap,\n\u001b[0;32m    181\u001b[0m                                         mask_img\u001b[39m=\u001b[39;49mmask_img)\n\u001b[0;32m    182\u001b[0m     \u001b[39mfor\u001b[39;00m i, row \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(A\u001b[39m.\u001b[39mrows):\n\u001b[0;32m    183\u001b[0m         \u001b[39myield\u001b[39;00m X[:, row]\n",
      "File \u001b[1;32mc:\\Users\\ciyer\\miniconda3\\envs\\lab\\Lib\\site-packages\\nilearn\\maskers\\nifti_spheres_masker.py:112\u001b[0m, in \u001b[0;36m_apply_mask_and_get_affinity\u001b[1;34m(seeds, niimg, radius, allow_overlap, mask_img)\u001b[0m\n\u001b[0;32m    110\u001b[0m nearest \u001b[39m=\u001b[39m (nearest[\u001b[39m0\u001b[39m], nearest[\u001b[39m1\u001b[39m], nearest[\u001b[39m2\u001b[39m])\n\u001b[0;32m    111\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 112\u001b[0m     nearests\u001b[39m.\u001b[39mappend(mask_coords\u001b[39m.\u001b[39mindex(nearest))\n\u001b[0;32m    113\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m    114\u001b[0m     nearests\u001b[39m.\u001b[39mappend(\u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file = glob.glob('data/rest/*.nii.gz')[0]\n",
    "sphere_radius=8, \n",
    "sphere_spacing=6\n",
    "\n",
    "masker_args = {\n",
    "    'standardize': 'zscore_sample', # ??\n",
    "    'n_jobs': -1,\n",
    "    # not doing any: mask_img, smoothing, detrend, standardize, low_pass, high_pass, t_r\n",
    "}\n",
    "sphere_coords = [] # get the centerpoint coordinates of spheres. These ranges from chatGPT so def need to check\n",
    "for x in range(-90, 91, sphere_spacing):\n",
    "    for y in range(-126, 91, sphere_spacing):\n",
    "        for z in range(-72, 73, sphere_spacing):\n",
    "            sphere_coords.append((x, y, z))\n",
    "masker = NiftiSpheresMasker(seeds = sphere_coords, \n",
    "                            radius=sphere_radius, \n",
    "                            **masker_args)\n",
    "# NOTE: change this to match dimensionality of whatever the others are outputting\n",
    "test = [masker.fit_transform(f) for f in FILE_PATHS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
